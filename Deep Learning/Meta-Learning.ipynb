{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-Learning\n",
    "\n",
    "## 1. Case\n",
    "- **Few-Shot Learning** [(Brendan Lake et al.)](https://www.cs.cmu.edu/~rsalakhu/papers/LakeEtAl2015Science.pdf): to learn new concepts from one or a few instances of that concept\n",
    "\n",
    "## 2. Idea\n",
    "- **Problem of AI systems**: Current AI systems can master a complex skill from scratch, using an understandably large amount of time and experience. However, if we want our agents to be able to acquire many skills and adapt to many environments, we cannot afford to train each skill in each setting from scratch. \n",
    "- **How to use meta-learning to address the above problem**: If the agents can learn how to learn new tasks faster by reusing previous experience, rather than considering each new task in isolation, they may be able to adapt intelligently to a wide variety of new, unseen situations. This approach of **learning to learn, or meta-learning**, is a key stepping stone towards versatile agents that can continually learn a wide variety of tasks throughout their lifetimes.\n",
    "- Meta-learning systems are trained by being exposed to **a large number of tasks** and are then tested in **their ability to learn new tasks**.\n",
    "- During meta-learning, the model is trained to **learn tasks** in the meta-training set.\n",
    "\n",
    "## 3. Methods\n",
    "- During meta-learning, there are two optimizations at play:\n",
    "    1. the learner, which learns new tasks\n",
    "    2. the meta-learner, which trains the learner. \n",
    "- Methods for meta-learning:\n",
    "    1. Recurrent model\n",
    "        * The meta-learner uses gradient descent, whereas the learner simply rolls out the recurrent network.\n",
    "        * Be less (meta-)efficient than other methods because the learner network needs to come up with its learning strategy from scratch\n",
    "    2. Metric Learning\n",
    "        * To learn a metric space\n",
    "        * The meta-learning is performed using gradient descent (or your favorite neural network optimizer), whereas the learner corresponds to a comparison scheme, e.g. nearest neighbors, in the meta-learned metric space.\n",
    "    3. Learning optimisers\n",
    "        * To learn an optimiser\n",
    "        * One network (the meta-learner) learns to update another network (the learner) so that the learner effectively learns the task. \n",
    "        \n",
    "## 4. Limitations of transfer learning\n",
    "- Typical steps of transfer learning:when approaching any new vision task, the well-known paradigm is to \n",
    "    1. collect labeled data for the task, \n",
    "    2. acquire a network pre-trained on ImageNet classification, and then \n",
    "    3. fine-tune the network (the last layer of the pre-trained network must be modified to adapt to the new labeled data) on the collected data using gradient descent.\n",
    "- Limitations:\n",
    "    1. For a very small dataset, e.g., in the few-shot learning setting, the number of labels are small, and the model can easliy go to overfitting.\n",
    "    2. For non-vision domains, such as speech, language, and control, there are no analogous pre-training schemes.\n",
    "- St:\n",
    "<img src='images/MAML.png' width=500>\n",
    "\n",
    "## 5. MAML [C. Finn et al.](https://arxiv.org/abs/1703.03400)\n",
    "- Model-Agnostic Meta-Learning (MAML) trains over a wide range of tasks\n",
    "- It trains for a representation that can be quickly adapted to a new task, via a few gradient steps. \n",
    "- **The meta-learner seeks to find an initialization** that is not only useful for adapting to various problems, but also can be adapted quickly (in a small number of steps) and efficiently (using only a few examples). \n",
    "- Suppose we are seeking to find a set of parameters θ that are highly adaptable. During the course of meta-learning (the bold line), MAML optimizes for a set of parameters such that when a gradient step is taken with respect to a particular task $i$ (the gray lines), the parameters are close to the optimal parameters $\\theta^∗_i$ for task $i$. See the visualisation below.\n",
    "\n",
    "<img src='images/MAML.png' width=500>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-4-prac]",
   "language": "python",
   "name": "conda-env-py3-4-prac-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
